{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm \n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#这行代码配置了:日志格式:时间-级别:日志信息日志级别:INFO时间格式:小时:分钟:秒\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s-%(levelname)s: %(message)s\",\\\n",
    "    level = logging.INFO,datefmt=\"%I:%H:%S\",filename='app.log',)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1alpha 和2加噪 公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RUNOOB 图标](alpha.png)\n",
    "![RUNOOB 图标](加噪.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](采样公式.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扩散模型（主要是采样）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Diffusion:\n",
    "    def __init__(self,nosie_steps=1000,beta_start=1e-4,beta_end=0.02,img_size=6,device=\"cuda\") -> None:\n",
    "        # 加噪步数\n",
    "        self.noise_steps = nosie_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "        #实现上面图片alpha公式\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        #torch.cumprod的作用是计算张量在指定维度上元素的累积积\n",
    "        self.alpha_hat = torch.cumprod(self.alpha,dim=0)\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start,self.beta_end,self.noise_steps)\n",
    "    # 对图片进行加噪 \n",
    "    def noise_images(self,x,t):\n",
    "        #对对应的时间步骤进行扩维 并且开根号\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:,None,None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1.- self.alpha_hat[t])[:,None,None]\n",
    "        z = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat*z\n",
    "        # 步骤列表\n",
    "    def sample_timesteps(self,n):\n",
    "        return torch.randint(low=1,high=self.noise_steps,size=(n,))\n",
    "    \n",
    "    def sample(self,model,n):\n",
    "        logging.info(f\"Sampling{n} new images\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n,3,self.img_size,self.img_size)).to(self.device)\n",
    "            #position=0 - 设置进度条位置为最上方\n",
    "            for i in tqdm(reversed(range(1,self.noise_images)),position=0):\n",
    "                t = (torch.ones(n)*i).long().to(self.device)#[1, 1, 1, 1, 1]\n",
    "                predict_noise = model(x,t)\n",
    "                alpha = self.alpha[t][:,None,None,None]\n",
    "                alpha_hat = self.alpha_hat[t][:,None,None,None]\n",
    "                beta = self.beta[t][:,None,None,None]\n",
    "                #最后一次去噪后不添加随机噪声\n",
    "                if i >1 :\n",
    "                    noise = torch.randn_like(x)\n",
    "                else :\n",
    "                    noise = torch.zeros_list(x)\n",
    "                x = 1/torch.sqrt(alpha) * (x-(1-alpha) /torch.sqrt(1-alpha) *predict_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        # 如果x中的元素原本小于-1,将被替换为-1;如果原本大于1,将被替换为1;如果在[-1, 1]范围内,保持不变\n",
    "        x = (x.clamp(-1,1)+1)/2\n",
    "        x = (x*255).type(torch.uint8)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3,time_dim=256,device=\"cuda\") -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc1 = DoubleConv(c_in,64)\n",
    "        self.down1 = Down(64,128)\n",
    "        self.sa1 = SelfAttention(128,32)\n",
    "        self.down2 = Down(128,256)\n",
    "        self.sa2 = selfSelfAttention(25,8)\n",
    "        self.down3 = Down(256,256)\n",
    "        self.sa3 = SelfAttention(256,8)\n",
    "        \n",
    "        self.bat1 = DoubleConv(256,512)\n",
    "        self.bot2 = DoubleConv(512,512)\n",
    "        self.bot3 = DoubleConv(512,256)\n",
    "        \n",
    "        self.up1 = Up(512,128)\n",
    "        self.sa4 = SelfAttention(128,16)\n",
    "        self.up2 = Up(256,64)\n",
    "        self.sa5 = SelfAttention(64,32)\n",
    "        self.up3 = SelfAttention(128,64)\n",
    "        self.sa6 = SelfAttention(6,6)\n",
    "        self.outc = nn.Conv2d(64,c_out,kernel_size=1)\n",
    "    # 位置编码\n",
    "    def pos_encoding(self,t, channels):\n",
    "        inv_freg = 1.0 / ( \n",
    "            10000 **\n",
    "            # 生成数列\n",
    "            (torch.arange(0,channels,2,device=self.device).float() /channels)\n",
    "        )\n",
    "        #t.repeat(1,channels //2 沿着1维度（还有0维度）复制多次\n",
    "        pos_enc_a = torch.sin(t.repeat(1,channels //2) *inv_freg)\n",
    "        pos_enc_b = torch.cos(t.repeat(1,channels //2)*inv_freg)\n",
    "        pos_enc = torch.cat([pos_enc_a,pos_enc_b],dim=-1)\n",
    "        \n",
    "        return pos_enc\n",
    "    # 这里开始写他的网络结构了\n",
    "    def forward(self,x,t):\n",
    "        # unsqueeze(-1)的作用是在张量t的最后一维增加单维度  如[5]变成[5,1]\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        #时间编码\n",
    "        t = self.pos_encoding(t,self.time_dim)\n",
    "        x1 = self.inc1(x)\n",
    "        x2 = self.down1(x1,t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2,t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.sa3(x4)\n",
    "        \n",
    "        \n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "        \n",
    "        x5 = self.up1(x4,t)\n",
    "        x5 = self.sa4(x5)\n",
    "        x6 = self.up2(x5,t)\n",
    "        x6 = self.sa5(x6)\n",
    "        x7 = self.up3(x6,t)\n",
    "        x7 = self.sa6(x7)\n",
    "        # 全卷积对空间信息敏感的任务,如图像分割、生成模型等,既保留了空间信息,又增加了灵活性\n",
    "        out = self.outc(x7)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各部分的小模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小模块 双层卷积可能还有残差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    # 残差的参数residual  ,mid_channels控制输出通道\n",
    "    def __init__(self,in_channels,out_channels,mid_channels=None,residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.doubleConv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,mid_channels,kernel_size=3,padding =1,bisa =False),\n",
    "            nn.GroupNorm(1,mid_channels),\n",
    "            # 在负值区有非零响应,不像ReLU直接切断，在正值区会增强大值,并压缩小值\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels,out_channels,3,1,bias=False),\n",
    "            # 将C个通道划分成G组,每组含C/G个通道。在每组内部分别计算均值和标准差,进行规范化。\n",
    "            #Layer Norm: 对每个样本进行规范化 ，Layer Norm针对样本维度计算,计算量大\n",
    "#Batch Norm: 对每个批量进行规范化，Batch Norm的计算量一般介于二者之间  Batch Norm收敛速度快,但对批量大小敏感\n",
    "#Group Norm: 对通道组进行规范化  Group Norm只在小组内计算,计算量较小 Group Norm和Layer Norm收敛稍慢,但鲁棒性更好\n",
    "            nn.GroupNorm(1,out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 两个卷积层之间有没有残差\n",
    "        if self.residual:\n",
    "            return F.gelu(x+self.doubleConv(x))\n",
    "        else :\n",
    "            return self.doubleConv(x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels,out_channels,residual=True),\n",
    "            DoubleConv(in_channels,out_channels)\n",
    "        )\n",
    "        #对采样的步骤的编码\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            # 负值有梯度没有\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(emb_dim,out_channels)\n",
    "        )\n",
    "    def forward(self,x,t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        #传入位置index ，t,得到位置编码向量  self.emb_layer(t) 有了批量大小的维度和通道数的维度，还要把图片大小宽高维度扩大\n",
    "        emb = self.emb_layer(t)[:,:,None,None].repeat(1,1,x.shape[-2],x.shape[-1])\n",
    "        # 把采样时刻和图片特征融合\n",
    "        return x+emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m help(torch\u001b[39m.\u001b[39;49mrepeat())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "class UP(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,emb_dim=256) -> None:\n",
    "        super().__init__()\n",
    "        # 双线性插值（新点周围的最近4个点按比例插值计算,这样可以得到更平滑的放大结果。）\n",
    "        # 不是用卷积可以是比较懒，或者太大的参数量不能计算\n",
    "        \n",
    "        self.up = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
    "        self. conv = nn.Sequential(\n",
    "            DoubleConv(in_channels,in_channels,residual=True),\n",
    "            DoubleConv(in_channels,out_channels,in_channels//2)\n",
    "        )\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            )\n",
    "        )\n",
    "    def forward(self,x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        # 拼接，1 是通道的维度，通道数相加\n",
    "        x = torch.cat([skip_x,x],dim = 1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)\n",
    "        return x + emb\n",
    "\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自注意力机制\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels,size) -> None:\n",
    "        super(SelfAttention,self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        #nn.MultiheadAttention模块中,batch_first是一个布尔类型的参数,它表示输入输出张量的格式是:\n",
    "\n",
    "         #batch_first=True: 输入/输出为 (batch, seq, feature)\n",
    "         #batch_first=False: 输入/输出为 (seq, batch, feature)\n",
    "         # channels 图片就是3，文字就是一个字的维度\n",
    "        self.mha = nn.MultiheadAttention(channels,4,batch_first=True)\n",
    "        self.ln = nn.LayerNorm(channels)\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels,channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels,channels)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        #x.view操作:将(batch_size, channels, H, W) 形状展平为 (batch_size, channels, H * W)\n",
    "        # swapaxes(1, 2)操作:将channels和H*W这两个维度调换顺序\n",
    "        # 换通道你想之前处理文字是通道在最后面，所以这里也要变成这样\n",
    "        #view()返回的是张量的视图(view),不会进行额外内存分配,更高效。\n",
    "        #reshape()返回的是重新分配内存的张量副本,占用更多内存\n",
    "        x = x.view(-1,self.channels,self.size *self.size).swapaxes(1,2)\n",
    "        x_ln = self.ln(x)\n",
    "        # 三个都是一样的自注意力 机制\n",
    "        attention_value,_ = self.mha(x_ln,x_ln,x_ln)\n",
    "        # 自注意力以及残差残差\n",
    "        attention_value =  attention_value+x\n",
    "        # 前项以及残差\n",
    "        attention_value = self.ff_self(attention_value) +attention_value \n",
    "        return attention_value.swapaxex(2,1).view(-1,self.channels,self.size,self.size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
